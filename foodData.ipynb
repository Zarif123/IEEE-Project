{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch imports\n",
    "import wget\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import models, transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import collections\n",
    "from shutil import copy\n",
    "from shutil import copytree, rmtree\n",
    "import random\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import math\n",
    "import time\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "bs = 64\n",
    "epochs = 3\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "imagenet_stats = [(0.485, 0.456, 0.406), (0.229, 0.224, 0.225)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOOD_PATH = \"./food-101\"\n",
    "IMG_PATH = FOOD_PATH+\"/images\"\n",
    "META_PATH = FOOD_PATH+\"/meta\"\n",
    "TRAIN_PATH = FOOD_PATH+\"/train\"\n",
    "VALID_PATH = FOOD_PATH+\"/valid\"\n",
    "MODEL_PATH = 'model_data/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "gpu = True if torch.cuda.is_available() else False\n",
    "gpu\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = MODEL_PATH+'clr.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pp_(*args, n_dash=120):\n",
    "    for arg in args:\n",
    "        print(arg)\n",
    "        print(\"-\"*n_dash)\n",
    "\n",
    "def list_dir(path=\"./\"): return os.listdir(path)\n",
    "\n",
    "def cal_mean_std(train_data):\n",
    "    return np.mean(train_data, axis=(0,1,2))/255, np.std(train_data, axis=(0,1,2))/255\n",
    "\n",
    "def save_checkpoint(model, is_best, filename='model_data/checkpoint.pth'):\n",
    "    \"\"\"Save checkpoint if a new best is achieved\"\"\"\n",
    "    if is_best:\n",
    "        torch.save(model.state_dict(), filename)  # save checkpoint\n",
    "    else:\n",
    "        print (\"=> Validation Accuracy did not improve\")\n",
    "        \n",
    "# from fastai library\n",
    "def load_checkpoint(model, filename = 'model_data/checkpoint.pth'):\n",
    "    sd = torch.load(filename, map_location=lambda storage, loc: storage)\n",
    "    names = set(model.state_dict().keys())\n",
    "    for n in list(sd.keys()): \n",
    "        if n not in names and n+'_raw' in names:\n",
    "            if n+'_raw' not in sd: sd[n+'_raw'] = sd[n]\n",
    "            del sd[n]\n",
    "    model.load_state_dict(sd)        \n",
    "\n",
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "    \n",
    "def load_model(model, path):\n",
    "    model.load_state_dict(torch.load(path))    \n",
    "\n",
    "def calc_iters(dataset, num_epochs, bs):\n",
    "    return int(len(dataset) * num_epochs /bs)\n",
    "\n",
    "def accuracy(output, target, is_test=False):\n",
    "    global total\n",
    "    global correct\n",
    "    batch_size = output.shape[0]\n",
    "    total += batch_size\n",
    "    \n",
    "    _, pred = torch.max(output, 1)\n",
    "    if is_test:\n",
    "        preds.extend(pred)\n",
    "    correct += (pred == target).sum()\n",
    "    return 100 * correct / total\n",
    "\n",
    "class AvgStats(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.losses =[]\n",
    "        self.precs =[]\n",
    "        self.its = []\n",
    "        \n",
    "    def append(self, loss, prec, it):\n",
    "        self.losses.append(loss)\n",
    "        self.precs.append(prec)\n",
    "        self.its.append(it)\n",
    "\n",
    "def freeze(model):\n",
    "    child_counter = 0\n",
    "    for name, child in model.named_children():\n",
    "        if child_counter < 7:\n",
    "            print(\"name \",name, \"child \",child_counter,\" was frozen\")\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = False\n",
    "        elif child_counter == 7:\n",
    "            children_of_child_counter = 0\n",
    "            for children_of_child in child.children():\n",
    "                if children_of_child_counter < 2:\n",
    "                    for param in children_of_child.parameters():\n",
    "                        param.requires_grad = False\n",
    "                    print(\"name \",name, 'child ', children_of_child_counter, 'of child',child_counter,' was frozen')\n",
    "                else:\n",
    "                    print(\"name \",name, 'child ', children_of_child_counter, 'of child',child_counter,' was not frozen')\n",
    "                children_of_child_counter += 1\n",
    "\n",
    "        else:\n",
    "            print(\"name \",name, \"child \",child_counter,\" was not frozen\")\n",
    "        child_counter += 1\n",
    "\n",
    "def unfreeze(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "def print_frozen_state(model):\n",
    "    child_counter = 0\n",
    "    for name, child in model.named_children():\n",
    "        for param in child.parameters():\n",
    "            if param.requires_grad == True:\n",
    "                print(\"child \",child_counter,\"named:\",name,\" is unfrezed\")\n",
    "            elif param.requires_grad == False:\n",
    "                print(\"child \",child_counter,\"named:\",name,\" is frezed\")\n",
    "        child_counter += 1\n",
    "\n",
    "def update_lr(optimizer, lr):\n",
    "    for g in optimizer.param_groups:\n",
    "        g['lr'] = lr\n",
    "\n",
    "def update_mom(optimizer, mom):\n",
    "    for g in optimizer.param_groups:\n",
    "        g['momentum'] = mom\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FOOD101():\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        self.bs = 64\n",
    "        self.epochs = 3\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.imagenet_stats = [(0.485, 0.456, 0.406), (0.229, 0.224, 0.225)]\n",
    "        self.train_ds, self.valid_ds, self.train_cls, self.valid_cls = [None]*4\n",
    "        self.imgenet_mean = self.imagenet_stats[0]\n",
    "        self.imgenet_std = self.imagenet_stats[1]\n",
    "   \n",
    "    def get_data_extract(self):\n",
    "        if \"food-101\" in os.listdir():\n",
    "            print(\"Dataset already exists\")\n",
    "        else:\n",
    "            print(\"Downloading the data...\")\n",
    "            wget.download(\"http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz\")\n",
    "            print(\"Dataset downloaded!\")\n",
    "            print(\"Extracting data..\")\n",
    "            # !tar xzvf food-101.tar.gz\n",
    "            print(\"Extraction done!\")\n",
    "        \n",
    "    def _get_tfms(self):\n",
    "        train_tfms = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(), \n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(self.imgenet_mean, self.imgenet_std)])\n",
    "        \n",
    "        valid_tfms = transforms.Compose([\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(self.imgenet_mean, self.imgenet_std)])        \n",
    "        return train_tfms, valid_tfms            \n",
    "            \n",
    "    def get_dataset(self,root_dir='./food-101/'):\n",
    "        train_tfms, valid_tfms = self._get_tfms() # transformations\n",
    "        self.train_ds = datasets.ImageFolder(root=TRAIN_PATH, transform=train_tfms)\n",
    "        self.valid_ds = datasets.ImageFolder(root=VALID_PATH, transform=valid_tfms)        \n",
    "        self.train_classes = self.train_ds.classes\n",
    "        self.valid_classes = self.valid_ds.classes\n",
    "\n",
    "        assert self.train_classes==self.valid_classes\n",
    "        return self.train_ds, self.valid_ds, self.train_classes\n",
    "\n",
    "    \n",
    "    def get_dls(self, train_ds, valid_ds, bs, **kwargs):\n",
    "        return (DataLoader(train_ds, batch_size=bs, shuffle=True, **kwargs),\n",
    "               DataLoader(valid_ds, batch_size=bs//2, shuffle=False, **kwargs))\n",
    "    \n",
    "food = FOOD101()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists\n"
     ]
    }
   ],
   "source": [
    "food.get_data_extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['images', 'license_agreement.txt', 'meta', 'README.txt', 'train', 'valid']\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "['apple_pie', 'baby_back_ribs', 'baklava', 'beef_carpaccio', 'beef_tartare', 'beet_salad', 'beignets', 'bibimbap', 'bread_pudding', 'breakfast_burrito', 'bruschetta', 'caesar_salad', 'cannoli', 'caprese_salad', 'carrot_cake', 'ceviche', 'cheesecake', 'cheese_plate', 'chicken_curry', 'chicken_quesadilla', 'chicken_wings', 'chocolate_cake', 'chocolate_mousse', 'churros', 'clam_chowder', 'club_sandwich', 'crab_cakes', 'creme_brulee', 'croque_madame', 'cup_cakes', 'deviled_eggs', 'donuts', 'dumplings', 'edamame', 'eggs_benedict', 'escargots', 'falafel', 'filet_mignon', 'fish_and_chips', 'foie_gras', 'french_fries', 'french_onion_soup', 'french_toast', 'fried_calamari', 'fried_rice', 'frozen_yogurt', 'garlic_bread', 'gnocchi', 'greek_salad', 'grilled_cheese_sandwich', 'grilled_salmon', 'guacamole', 'gyoza', 'hamburger', 'hot_and_sour_soup', 'hot_dog', 'huevos_rancheros', 'hummus', 'ice_cream', 'lasagna', 'lobster_bisque', 'lobster_roll_sandwich', 'macaroni_and_cheese', 'macarons', 'miso_soup', 'mussels', 'nachos', 'omelette', 'onion_rings', 'oysters', 'pad_thai', 'paella', 'pancakes', 'panna_cotta', 'peking_duck', 'pho', 'pizza', 'pork_chop', 'poutine', 'prime_rib', 'pulled_pork_sandwich', 'ramen', 'ravioli', 'red_velvet_cake', 'risotto', 'samosa', 'sashimi', 'scallops', 'seaweed_salad', 'shrimp_and_grits', 'spaghetti_bolognese', 'spaghetti_carbonara', 'spring_rolls', 'steak', 'strawberry_shortcake', 'sushi', 'tacos', 'takoyaki', 'tiramisu', 'tuna_tartare', 'waffles']\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "['classes.txt', 'labels.txt', 'test.json', 'test.txt', 'train.json', 'train.txt']\n",
      "------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "pp_(list_dir(FOOD_PATH), list_dir(IMG_PATH), list_dir(META_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper method to split dataset into train and test folders\n",
    "def prepare_data(filepath, src, dest):\n",
    "    classes_images = defaultdict(list)\n",
    "    with open(filepath, 'r') as txt:\n",
    "        paths = [read.strip() for read in txt.readlines()]\n",
    "        for p in paths:\n",
    "            food = p.split('/')\n",
    "            classes_images[food[0]].append(food[1] + '.jpg')\n",
    "\n",
    "    for food in classes_images.keys():\n",
    "        print(\"\\nCopying images into \",food)\n",
    "        if not os.path.exists(os.path.join(dest,food)):\n",
    "            os.makedirs(os.path.join(dest,food))\n",
    "        for i in classes_images[food]:\n",
    "            copy(os.path.join(src,food,i), os.path.join(dest,food,i))\n",
    "    print(\"Copying Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Copying images into  apple_pie\n",
      "\n",
      "Copying images into  baby_back_ribs\n",
      "\n",
      "Copying images into  baklava\n",
      "\n",
      "Copying images into  beef_carpaccio\n",
      "\n",
      "Copying images into  beef_tartare\n",
      "\n",
      "Copying images into  beet_salad\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m prepare_data(META_PATH\u001b[39m+\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m/train.txt\u001b[39;49m\u001b[39m'\u001b[39;49m, IMG_PATH, TRAIN_PATH)\n\u001b[0;32m      2\u001b[0m prepare_data(META_PATH\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/test.txt\u001b[39m\u001b[39m'\u001b[39m, IMG_PATH, VALID_PATH)\n",
      "Cell \u001b[1;32mIn[21], line 15\u001b[0m, in \u001b[0;36mprepare_data\u001b[1;34m(filepath, src, dest)\u001b[0m\n\u001b[0;32m     13\u001b[0m         os\u001b[39m.\u001b[39mmakedirs(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(dest,food))\n\u001b[0;32m     14\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m classes_images[food]:\n\u001b[1;32m---> 15\u001b[0m         copy(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(src,food,i), os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(dest,food,i))\n\u001b[0;32m     16\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCopying Done!\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\yumin\\miniconda3\\lib\\shutil.py:418\u001b[0m, in \u001b[0;36mcopy\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(dst):\n\u001b[0;32m    417\u001b[0m     dst \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(dst, os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mbasename(src))\n\u001b[1;32m--> 418\u001b[0m copyfile(src, dst, follow_symlinks\u001b[39m=\u001b[39;49mfollow_symlinks)\n\u001b[0;32m    419\u001b[0m copymode(src, dst, follow_symlinks\u001b[39m=\u001b[39mfollow_symlinks)\n\u001b[0;32m    420\u001b[0m \u001b[39mreturn\u001b[39;00m dst\n",
      "File \u001b[1;32mc:\\Users\\yumin\\miniconda3\\lib\\shutil.py:282\u001b[0m, in \u001b[0;36mcopyfile\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[39m# Windows, see:\u001b[39;00m\n\u001b[0;32m    280\u001b[0m \u001b[39m# https://github.com/python/cpython/pull/7160#discussion_r195405230\u001b[39;00m\n\u001b[0;32m    281\u001b[0m \u001b[39melif\u001b[39;00m _WINDOWS \u001b[39mand\u001b[39;00m file_size \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 282\u001b[0m     _copyfileobj_readinto(fsrc, fdst, \u001b[39mmin\u001b[39;49m(file_size, COPY_BUFSIZE))\n\u001b[0;32m    283\u001b[0m     \u001b[39mreturn\u001b[39;00m dst\n\u001b[0;32m    285\u001b[0m copyfileobj(fsrc, fdst)\n",
      "File \u001b[1;32mc:\\Users\\yumin\\miniconda3\\lib\\shutil.py:195\u001b[0m, in \u001b[0;36m_copyfileobj_readinto\u001b[1;34m(fsrc, fdst, length)\u001b[0m\n\u001b[0;32m    193\u001b[0m         fdst\u001b[39m.\u001b[39mwrite(smv)\n\u001b[0;32m    194\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 195\u001b[0m     fdst_write(mv)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "prepare_data(META_PATH+'/train.txt', IMG_PATH, TRAIN_PATH)\n",
    "prepare_data(META_PATH+'/test.txt', IMG_PATH, VALID_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple_pie', 'baby_back_ribs', 'baklava', 'beef_carpaccio', 'beef_tartare', 'beet_salad', 'beignets', 'bibimbap', 'bread_pudding', 'breakfast_burrito', 'bruschetta', 'caesar_salad', 'cannoli', 'caprese_salad', 'carrot_cake', 'ceviche', 'cheese_plate', 'cheesecake', 'chicken_curry', 'chicken_quesadilla', 'chicken_wings', 'chocolate_cake', 'chocolate_mousse', 'churros', 'clam_chowder', 'club_sandwich', 'crab_cakes', 'creme_brulee', 'croque_madame', 'cup_cakes', 'deviled_eggs', 'donuts', 'dumplings', 'edamame', 'eggs_benedict', 'escargots', 'falafel', 'filet_mignon', 'fish_and_chips', 'foie_gras', 'french_fries', 'french_onion_soup', 'french_toast', 'fried_calamari', 'fried_rice', 'frozen_yogurt', 'garlic_bread', 'gnocchi', 'greek_salad', 'grilled_cheese_sandwich', 'grilled_salmon', 'guacamole', 'gyoza', 'hamburger', 'hot_and_sour_soup', 'hot_dog', 'huevos_rancheros', 'hummus', 'ice_cream', 'lasagna', 'lobster_bisque', 'lobster_roll_sandwich', 'macaroni_and_cheese', 'macarons', 'miso_soup', 'mussels', 'nachos', 'omelette', 'onion_rings', 'oysters', 'pad_thai', 'paella', 'pancakes', 'panna_cotta', 'peking_duck', 'pho', 'pizza', 'pork_chop', 'poutine', 'prime_rib', 'pulled_pork_sandwich', 'ramen', 'ravioli', 'red_velvet_cake', 'risotto', 'samosa', 'sashimi', 'scallops', 'seaweed_salad', 'shrimp_and_grits', 'spaghetti_bolognese', 'spaghetti_carbonara', 'spring_rolls', 'steak', 'strawberry_shortcake', 'sushi', 'tacos', 'takoyaki', 'tiramisu', 'tuna_tartare', 'waffles']\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "101\n",
      "------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "train_ds, valid_ds, classes =  food.get_dataset()\n",
    "num_classes = len(classes)\n",
    "pp_(classes,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, valid_dl = food.get_dls(train_ds, valid_ds, bs=bs, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataBunch():\n",
    "    def __init__(self, train_dl, valid_dl, c=None):\n",
    "        self.train_dl, self.valid_dl, self.c = train_dl, valid_dl, c\n",
    "    \n",
    "    @property\n",
    "    def train_ds(self): return self.train_dl.dataset\n",
    "    \n",
    "    @property\n",
    "    def valid_ds(self): return self.valid_dl.dataset\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self.__class__.__name__)+\" obj (train & valid DataLoaders)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataBunch(train_dl, valid_dl, c=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 25250\n",
      "    Root location: ./food-101/valid\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               CenterCrop(size=(224, 224))\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
      "           )\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "101\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Dataset ImageFolder\n",
      "    Number of datapoints: 75750\n",
      "    Root location: ./food-101/train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               RandomResizedCrop(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear), antialias=None)\n",
      "               RandomHorizontalFlip(p=0.5)\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
      "           )\n",
      "------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "pp_(data.valid_ds, data.c, data.train_ds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_ds(trainset, classes, validset=None, cols=6, rows=17, preds=None, is_pred=False, is_valid=False):        \n",
    "    fig = plt.figure(figsize=(25,25))\n",
    "    fig.suptitle(f\"Showing one random image from each {'Validation' if is_valid else 'Train'} classes\", y=0.92, fontsize=24) # Adding  y=1.05, fontsize=24 helped me fix the suptitle overlapping with axes issue\n",
    "    columns = cols\n",
    "    rows = rows\n",
    "    \n",
    "    imgenet_mean = imagenet_stats[0]\n",
    "    imgenet_std = imagenet_stats[1]  \n",
    "\n",
    "    for i in range(1, columns*rows +1):\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        \n",
    "        if is_pred and testset:\n",
    "            img_xy = np.random.randint(len(testset));\n",
    "            np_img = testset[img_xy][0].numpy()\n",
    "            img = np.transpose(np_img, (1,2,0))            \n",
    "            img = img * imgenet_std + imgenet_mean\n",
    "        else:\n",
    "            img_xy = np.random.randint(len(trainset));\n",
    "            np_img = trainset[img_xy][0].numpy()\n",
    "            img = np.transpose(np_img, (1,2,0))\n",
    "            img = img * imgenet_std + imgenet_mean\n",
    "        \n",
    "        if is_pred:\n",
    "            plt.title(classes[int(preds[img_xy])] + \"/\" + classes[testset[img_xy][1]])\n",
    "        else:\n",
    "            plt.title(classes[trainset[img_xy][1]])\n",
    "        plt.axis('off')\n",
    "        img = np.clip(img, 0, 1)\n",
    "        plt.imshow(img, interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_ds(data.train_ds, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flask\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5) # convolutional layers\n",
    "        self.pool = nn.MaxPool2d(2, 2) # size of pool for image\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120) # this down is all the hidden layrs\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 101)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x)) # activation functions\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224])\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(data.train_ds[1][0].size())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "07e249ce8e44eea9a344c53d15b5bfd0eed07ddf06fa52c7efb21d2dcb80ee6b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
